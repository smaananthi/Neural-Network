{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1ed558",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61512f87",
   "metadata": {},
   "source": [
    "The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. \n",
    "The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n",
    "\n",
    "\n",
    "\n",
    "Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b8b47c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warningsimport tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f5795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = pd.read_csv(\"forestfires.csv\")\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a48eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ft.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f599bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe8a507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14a0f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e52bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows :\n"
     ]
    }
   ],
   "source": [
    "duplicate = ft[ft.duplicated()]\n",
    "print(\"Duplicate Rows :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8d563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder=preprocessing.LabelEncoder()\n",
    "ft['size_categ']=label_encoder.fit_transform(ft['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c58e83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "      <th>size_categ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size_category  size_categ\n",
       "0         small           1\n",
       "1         small           1\n",
       "2         small           1\n",
       "3         small           1\n",
       "4         small           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft[['size_category','size_categ']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61148913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_categ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_categ  \n",
       "0           0         0           1  \n",
       "1           1         0           1  \n",
       "2           1         0           1  \n",
       "3           0         0           1  \n",
       "4           0         0           1  \n",
       "..        ...       ...         ...  \n",
       "512         0         0           0  \n",
       "513         0         0           0  \n",
       "514         0         0           0  \n",
       "515         0         0           1  \n",
       "516         0         0           1  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft1=ft.drop(columns=(['month','day','size_category']),axis=1)\n",
    "ft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0cb0b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area',\n",
       "       'dayfri', 'daymon', 'daysat', 'daysun', 'daythu', 'daytue', 'daywed',\n",
       "       'monthapr', 'monthaug', 'monthdec', 'monthfeb', 'monthjan', 'monthjul',\n",
       "       'monthjun', 'monthmar', 'monthmay', 'monthnov', 'monthoct', 'monthsep',\n",
       "       'size_categ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc8ba2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add69c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  daymon\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1       0\n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0       0\n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0       0\n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1       0\n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0       0\n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...     ...\n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0       0\n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0       0\n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0       0\n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0       0\n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0       0\n",
       "\n",
       "[517 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=ft1.iloc[:,0:11]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "666d7564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    1\n",
       "516    1\n",
       "Name: size_categ, Length: 517, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ft1.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575a04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edd1a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb11b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e3684c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "265ad926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ee92d",
   "metadata": {},
   "source": [
    "# Batch Size and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d26bd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=11,  activation='relu')) #1st layer\n",
    "model.add(Dense(11,  activation='relu')) #2nd layer\n",
    "model.add(Dense(1, activation='sigmoid')) #3rd layer or op layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1cdb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss ='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cea7377c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 50.5584 - accuracy: 0.3699 - val_loss: 14.9977 - val_accuracy: 0.6784\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.2493 - accuracy: 0.7110 - val_loss: 4.3770 - val_accuracy: 0.6550\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5340 - accuracy: 0.7370 - val_loss: 4.7456 - val_accuracy: 0.7368\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.0198 - accuracy: 0.7457 - val_loss: 4.0339 - val_accuracy: 0.7018\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.7105 - accuracy: 0.7572 - val_loss: 3.8273 - val_accuracy: 0.7193\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4385 - accuracy: 0.7428 - val_loss: 2.9344 - val_accuracy: 0.6901\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.2365 - accuracy: 0.7746 - val_loss: 3.6554 - val_accuracy: 0.7018\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.7688 - val_loss: 2.5442 - val_accuracy: 0.7368\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.8035 - val_loss: 2.0987 - val_accuracy: 0.7602\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.8006 - val_loss: 2.0793 - val_accuracy: 0.7544\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8439 - val_loss: 0.8899 - val_accuracy: 0.8070\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8671 - val_loss: 0.7692 - val_accuracy: 0.8012\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8902 - val_loss: 0.4192 - val_accuracy: 0.8772\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9162 - val_loss: 0.3554 - val_accuracy: 0.8713\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1967 - accuracy: 0.9249 - val_loss: 0.3296 - val_accuracy: 0.8713\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9306 - val_loss: 0.3926 - val_accuracy: 0.8713\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9249 - val_loss: 0.3096 - val_accuracy: 0.8655\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9480 - val_loss: 0.3023 - val_accuracy: 0.8830\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9133 - val_loss: 0.4546 - val_accuracy: 0.8129\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9566 - val_loss: 0.2717 - val_accuracy: 0.8713\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9566 - val_loss: 0.2716 - val_accuracy: 0.8947\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9624 - val_loss: 0.3046 - val_accuracy: 0.8713\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9595 - val_loss: 0.3403 - val_accuracy: 0.8655\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9451 - val_loss: 0.2242 - val_accuracy: 0.9006\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9653 - val_loss: 0.2235 - val_accuracy: 0.8830\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9566 - val_loss: 0.4159 - val_accuracy: 0.8304\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.9595 - val_loss: 0.4956 - val_accuracy: 0.8538\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9566 - val_loss: 0.1993 - val_accuracy: 0.9240\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9538 - val_loss: 0.3198 - val_accuracy: 0.8830\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9566 - val_loss: 0.2048 - val_accuracy: 0.9064\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9711 - val_loss: 0.2160 - val_accuracy: 0.9006\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9624 - val_loss: 0.2478 - val_accuracy: 0.8947\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9509 - val_loss: 0.2846 - val_accuracy: 0.8830\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9682 - val_loss: 0.2600 - val_accuracy: 0.9006\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9538 - val_loss: 0.2455 - val_accuracy: 0.9123\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9538 - val_loss: 0.1426 - val_accuracy: 0.9474\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9769 - val_loss: 0.2217 - val_accuracy: 0.9006\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1832 - accuracy: 0.9364 - val_loss: 0.1460 - val_accuracy: 0.9532\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.1467 - val_accuracy: 0.9591\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9682 - val_loss: 0.2530 - val_accuracy: 0.9006\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9364 - val_loss: 0.1518 - val_accuracy: 0.9474\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 0.1605 - val_accuracy: 0.9123\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9566 - val_loss: 0.1342 - val_accuracy: 0.9532\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9740 - val_loss: 0.1362 - val_accuracy: 0.9532\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9740 - val_loss: 0.1925 - val_accuracy: 0.9064\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.1552 - val_accuracy: 0.9181\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9711 - val_loss: 0.1517 - val_accuracy: 0.9357\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9798 - val_loss: 0.1227 - val_accuracy: 0.9532\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.1202 - val_accuracy: 0.9591\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.9769 - val_loss: 0.3548 - val_accuracy: 0.8538\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9711 - val_loss: 0.1169 - val_accuracy: 0.9532\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9653 - val_loss: 0.1177 - val_accuracy: 0.9532\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9711 - val_loss: 0.1364 - val_accuracy: 0.9357\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 0.2393 - val_accuracy: 0.8947\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9711 - val_loss: 0.1412 - val_accuracy: 0.9240\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.5962 - val_accuracy: 0.7661\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8873 - val_loss: 0.1329 - val_accuracy: 0.9181\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9682 - val_loss: 0.5123 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9422 - val_loss: 0.2042 - val_accuracy: 0.9123\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9364 - val_loss: 0.0973 - val_accuracy: 0.9591\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9451 - val_loss: 0.3421 - val_accuracy: 0.8947\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9538 - val_loss: 0.1550 - val_accuracy: 0.9181\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9509 - val_loss: 0.1915 - val_accuracy: 0.9181\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9769 - val_loss: 0.1337 - val_accuracy: 0.9415\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9769 - val_loss: 0.2382 - val_accuracy: 0.9123\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9942 - val_loss: 0.1162 - val_accuracy: 0.9532\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9798 - val_loss: 0.1612 - val_accuracy: 0.9240\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9884 - val_loss: 0.1337 - val_accuracy: 0.9298\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9913 - val_loss: 0.3701 - val_accuracy: 0.8889\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9740 - val_loss: 0.0976 - val_accuracy: 0.9532\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9509 - val_loss: 0.0919 - val_accuracy: 0.9649\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9855 - val_loss: 0.1270 - val_accuracy: 0.9298\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9798 - val_loss: 0.1874 - val_accuracy: 0.9240\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9653 - val_loss: 0.2594 - val_accuracy: 0.9006\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 0.2021 - val_accuracy: 0.9064\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.0901 - val_accuracy: 0.9591\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9971 - val_loss: 0.1088 - val_accuracy: 0.9474\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9855 - val_loss: 0.1917 - val_accuracy: 0.9064\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.1021 - val_accuracy: 0.9474\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9364 - val_loss: 0.1046 - val_accuracy: 0.9532\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9653 - val_loss: 0.2972 - val_accuracy: 0.8772\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9740 - val_loss: 0.0953 - val_accuracy: 0.9591\n",
      "Epoch 83/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9827 - val_loss: 0.1547 - val_accuracy: 0.9357\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9798 - val_loss: 0.1336 - val_accuracy: 0.9474\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9827 - val_loss: 0.1085 - val_accuracy: 0.9474\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9653 - val_loss: 0.0938 - val_accuracy: 0.9474\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9306 - val_loss: 3.0920 - val_accuracy: 0.8129\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.9220 - val_loss: 0.4945 - val_accuracy: 0.8830\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9740 - val_loss: 0.1889 - val_accuracy: 0.9123\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9769 - val_loss: 0.2960 - val_accuracy: 0.8772\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.1993 - val_accuracy: 0.9240\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9595 - val_loss: 0.1424 - val_accuracy: 0.9474\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9393 - val_loss: 0.1422 - val_accuracy: 0.9474\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9798 - val_loss: 0.0881 - val_accuracy: 0.9532\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.1295 - val_accuracy: 0.9532\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9798 - val_loss: 0.0788 - val_accuracy: 0.9532\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 0.4287 - val_accuracy: 0.8830\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9451 - val_loss: 0.9091 - val_accuracy: 0.8538\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9595 - val_loss: 0.2180 - val_accuracy: 0.9123\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9798 - val_loss: 0.0748 - val_accuracy: 0.9649\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9827 - val_loss: 0.2961 - val_accuracy: 0.9006\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9740 - val_loss: 0.2808 - val_accuracy: 0.9064\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9769 - val_loss: 0.1403 - val_accuracy: 0.9532\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9798 - val_loss: 0.7529 - val_accuracy: 0.8070\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9653 - val_loss: 0.0868 - val_accuracy: 0.9591\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9653 - val_loss: 0.2701 - val_accuracy: 0.9064\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9277 - val_loss: 0.0940 - val_accuracy: 0.9649\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9971 - val_loss: 0.1450 - val_accuracy: 0.9474\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9740 - val_loss: 0.1097 - val_accuracy: 0.9474\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9653 - val_loss: 0.1500 - val_accuracy: 0.9415\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9711 - val_loss: 0.1421 - val_accuracy: 0.9474\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 0.0979 - val_accuracy: 0.9532\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9827 - val_loss: 0.1171 - val_accuracy: 0.9474\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9798 - val_loss: 0.1196 - val_accuracy: 0.9474\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.1010 - val_accuracy: 0.9591\n",
      "Epoch 116/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9884 - val_loss: 0.2132 - val_accuracy: 0.9357\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9769 - val_loss: 0.3865 - val_accuracy: 0.8947\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9624 - val_loss: 0.3302 - val_accuracy: 0.8947\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.0892 - val_accuracy: 0.9591\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9335 - val_loss: 0.8753 - val_accuracy: 0.8713\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9913 - val_loss: 0.1917 - val_accuracy: 0.9415\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9827 - val_loss: 0.0890 - val_accuracy: 0.9591\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9827 - val_loss: 0.0866 - val_accuracy: 0.9591\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9827 - val_loss: 0.2102 - val_accuracy: 0.9240\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9653 - val_loss: 0.2332 - val_accuracy: 0.9240\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.2104 - val_accuracy: 0.9298\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.2826 - val_accuracy: 0.9006\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9827 - val_loss: 0.1925 - val_accuracy: 0.9532\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9711 - val_loss: 0.4835 - val_accuracy: 0.8889\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9595 - val_loss: 0.7202 - val_accuracy: 0.8713\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9855 - val_loss: 0.2848 - val_accuracy: 0.9006\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.1366 - val_accuracy: 0.9474\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9827 - val_loss: 0.9591 - val_accuracy: 0.8713\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9769 - val_loss: 0.0842 - val_accuracy: 0.9649\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9682 - val_loss: 0.3577 - val_accuracy: 0.8947\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9653 - val_loss: 1.0392 - val_accuracy: 0.8070\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9682 - val_loss: 0.0969 - val_accuracy: 0.9649\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9711 - val_loss: 0.1506 - val_accuracy: 0.9591\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9682 - val_loss: 0.7852 - val_accuracy: 0.8480\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.9538 - val_loss: 1.3277 - val_accuracy: 0.8713\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9855 - val_loss: 0.3116 - val_accuracy: 0.9181\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9740 - val_loss: 0.0885 - val_accuracy: 0.9649\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.0933 - val_accuracy: 0.9649\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.1165 - val_accuracy: 0.9532\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9827 - val_loss: 0.0918 - val_accuracy: 0.9649\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.1941 - val_accuracy: 0.9357\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9855 - val_loss: 0.0852 - val_accuracy: 0.9532\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.2239 - val_accuracy: 0.9298\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9827 - val_loss: 0.1118 - val_accuracy: 0.9591\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.1373 - val_accuracy: 0.9474\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9769 - val_loss: 0.0768 - val_accuracy: 0.9649\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9884 - val_loss: 0.4223 - val_accuracy: 0.9006\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9740 - val_loss: 0.1981 - val_accuracy: 0.9474\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9798 - val_loss: 0.3874 - val_accuracy: 0.9006\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9798 - val_loss: 0.0943 - val_accuracy: 0.9532\n",
      "Epoch 156/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9827 - val_loss: 0.1114 - val_accuracy: 0.9532\n",
      "Epoch 157/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.9740 - val_loss: 0.0806 - val_accuracy: 0.9649\n",
      "Epoch 158/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.1836 - val_accuracy: 0.9591\n",
      "Epoch 159/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9653 - val_loss: 0.1698 - val_accuracy: 0.9591\n",
      "Epoch 160/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 0.2161 - val_accuracy: 0.9415\n",
      "Epoch 161/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 0.1171 - val_accuracy: 0.9532\n",
      "Epoch 162/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9682 - val_loss: 0.1989 - val_accuracy: 0.9415\n",
      "Epoch 163/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9740 - val_loss: 0.1224 - val_accuracy: 0.9591\n",
      "Epoch 164/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9884 - val_loss: 0.0980 - val_accuracy: 0.9649\n",
      "Epoch 165/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.1196 - val_accuracy: 0.9591\n",
      "Epoch 166/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9357\n",
      "Epoch 167/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9624 - val_loss: 0.1079 - val_accuracy: 0.9591\n",
      "Epoch 168/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.1249 - val_accuracy: 0.9591\n",
      "Epoch 169/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9769 - val_loss: 0.1486 - val_accuracy: 0.9649\n",
      "Epoch 170/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9769 - val_loss: 0.0760 - val_accuracy: 0.9591\n",
      "Epoch 171/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9884 - val_loss: 0.0830 - val_accuracy: 0.9766\n",
      "Epoch 172/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.0820 - val_accuracy: 0.9708\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0845 - val_accuracy: 0.9415\n",
      "Epoch 174/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9855 - val_loss: 1.1580 - val_accuracy: 0.8772\n",
      "Epoch 175/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9595 - val_loss: 0.0832 - val_accuracy: 0.9649\n",
      "Epoch 176/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9913 - val_loss: 0.0862 - val_accuracy: 0.9415\n",
      "Epoch 177/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9740 - val_loss: 0.0846 - val_accuracy: 0.9649\n",
      "Epoch 178/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9942 - val_loss: 0.0836 - val_accuracy: 0.9591\n",
      "Epoch 179/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.2323 - val_accuracy: 0.9357\n",
      "Epoch 180/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9855 - val_loss: 0.1054 - val_accuracy: 0.9591\n",
      "Epoch 181/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0823 - val_accuracy: 0.9708\n",
      "Epoch 182/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9942 - val_loss: 0.1035 - val_accuracy: 0.9532\n",
      "Epoch 183/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0854 - val_accuracy: 0.9591\n",
      "Epoch 184/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9827 - val_loss: 0.0856 - val_accuracy: 0.9415\n",
      "Epoch 185/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9798 - val_loss: 0.1029 - val_accuracy: 0.9532\n",
      "Epoch 186/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9913 - val_loss: 0.1002 - val_accuracy: 0.9649\n",
      "Epoch 187/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9682 - val_loss: 0.1430 - val_accuracy: 0.9591\n",
      "Epoch 188/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.0989 - val_accuracy: 0.9591\n",
      "Epoch 189/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9884 - val_loss: 0.3578 - val_accuracy: 0.9181\n",
      "Epoch 190/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9711 - val_loss: 0.0913 - val_accuracy: 0.9532\n",
      "Epoch 191/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9740 - val_loss: 0.1861 - val_accuracy: 0.9591\n",
      "Epoch 192/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9798 - val_loss: 0.0949 - val_accuracy: 0.9532\n",
      "Epoch 193/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.1112 - val_accuracy: 0.9532\n",
      "Epoch 194/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.2929 - val_accuracy: 0.9357\n",
      "Epoch 195/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.4067 - val_accuracy: 0.9181\n",
      "Epoch 196/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9682 - val_loss: 0.2366 - val_accuracy: 0.9474\n",
      "Epoch 197/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9624 - val_loss: 0.2471 - val_accuracy: 0.9298\n",
      "Epoch 198/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9740 - val_loss: 0.2733 - val_accuracy: 0.9240\n",
      "Epoch 199/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9884 - val_loss: 0.0803 - val_accuracy: 0.9766\n",
      "Epoch 200/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9884 - val_loss: 0.0764 - val_accuracy: 0.9532\n",
      "Epoch 201/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.0830 - val_accuracy: 0.9649\n",
      "Epoch 202/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.1060 - val_accuracy: 0.9591\n",
      "Epoch 203/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9827 - val_loss: 0.0843 - val_accuracy: 0.9474\n",
      "Epoch 204/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0962 - val_accuracy: 0.9708\n",
      "Epoch 205/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9884 - val_loss: 0.0995 - val_accuracy: 0.9708\n",
      "Epoch 206/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9827 - val_loss: 0.0858 - val_accuracy: 0.9532\n",
      "Epoch 207/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1132 - val_accuracy: 0.9532\n",
      "Epoch 208/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9740 - val_loss: 0.5312 - val_accuracy: 0.8830\n",
      "Epoch 209/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9653 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 210/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9624 - val_loss: 0.6120 - val_accuracy: 0.9123\n",
      "Epoch 211/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9855 - val_loss: 0.1019 - val_accuracy: 0.9649\n",
      "Epoch 212/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9942 - val_loss: 0.1110 - val_accuracy: 0.9532\n",
      "Epoch 213/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9798 - val_loss: 0.3729 - val_accuracy: 0.9240\n",
      "Epoch 214/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9509 - val_loss: 1.7682 - val_accuracy: 0.8772\n",
      "Epoch 215/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9653 - val_loss: 0.1854 - val_accuracy: 0.9591\n",
      "Epoch 216/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9827 - val_loss: 0.6197 - val_accuracy: 0.8947\n",
      "Epoch 217/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9884 - val_loss: 0.0949 - val_accuracy: 0.9649\n",
      "Epoch 218/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9624 - val_loss: 0.2344 - val_accuracy: 0.9415\n",
      "Epoch 219/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9855 - val_loss: 0.3337 - val_accuracy: 0.9415\n",
      "Epoch 220/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9653 - val_loss: 1.1712 - val_accuracy: 0.8772\n",
      "Epoch 221/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9798 - val_loss: 0.1299 - val_accuracy: 0.9649\n",
      "Epoch 222/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.3781 - val_accuracy: 0.9357\n",
      "Epoch 223/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9798 - val_loss: 0.1241 - val_accuracy: 0.9649\n",
      "Epoch 224/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9827 - val_loss: 0.1084 - val_accuracy: 0.9591\n",
      "Epoch 225/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9682 - val_loss: 0.1196 - val_accuracy: 0.9532\n",
      "Epoch 226/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9855 - val_loss: 0.1754 - val_accuracy: 0.9591\n",
      "Epoch 227/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9566 - val_loss: 0.1967 - val_accuracy: 0.9474\n",
      "Epoch 228/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.1084 - val_accuracy: 0.9649\n",
      "Epoch 229/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1101 - val_accuracy: 0.9591\n",
      "Epoch 230/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9942 - val_loss: 0.1176 - val_accuracy: 0.9708\n",
      "Epoch 231/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.4194 - val_accuracy: 0.9357\n",
      "Epoch 232/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9827 - val_loss: 0.3549 - val_accuracy: 0.9240\n",
      "Epoch 233/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.1149 - val_accuracy: 0.9649\n",
      "Epoch 234/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9711 - val_loss: 0.1286 - val_accuracy: 0.9532\n",
      "Epoch 235/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9884 - val_loss: 0.2073 - val_accuracy: 0.9474\n",
      "Epoch 236/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.3878 - val_accuracy: 0.9240\n",
      "Epoch 237/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9855 - val_loss: 0.1620 - val_accuracy: 0.9591\n",
      "Epoch 238/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9942 - val_loss: 0.1888 - val_accuracy: 0.9591\n",
      "Epoch 239/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.1710 - val_accuracy: 0.9532\n",
      "Epoch 240/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.1151 - val_accuracy: 0.9532\n",
      "Epoch 241/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.1917 - val_accuracy: 0.9591\n",
      "Epoch 242/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9971 - val_loss: 0.2305 - val_accuracy: 0.9591\n",
      "Epoch 243/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9798 - val_loss: 0.2683 - val_accuracy: 0.9357\n",
      "Epoch 244/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9855 - val_loss: 0.1153 - val_accuracy: 0.9474\n",
      "Epoch 245/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9827 - val_loss: 0.1157 - val_accuracy: 0.9474\n",
      "Epoch 246/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.1331 - val_accuracy: 0.9532\n",
      "Epoch 247/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9884 - val_loss: 0.3218 - val_accuracy: 0.9298\n",
      "Epoch 248/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.1284 - val_accuracy: 0.9591\n",
      "Epoch 249/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9740 - val_loss: 0.8270 - val_accuracy: 0.8947\n",
      "Epoch 250/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9653 - val_loss: 0.1427 - val_accuracy: 0.9591\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y,validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aed260e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9845\n",
      "accuracy: 98.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cce25690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0beebbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all data in history\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23e4db17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61e7ffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e976aa3",
   "metadata": {},
   "source": [
    "# Learning rate and drop out rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a50685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(11,input_dim = 11,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(14,input_dim = 11,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(lr = learning_rate)\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = adam,\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ae029c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 0,batch_size = 40,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f83fd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad6ecab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   3.9s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.670 total time=   3.5s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.748 total time=   3.5s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.767 total time=   3.7s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.718 total time=   3.5s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.777 total time=   3.3s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.816 total time=   3.4s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.769 total time=   4.1s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.777 total time=   3.5s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.806 total time=   3.5s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.835 total time=   3.5s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.750 total time=   3.8s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.689 total time=   3.6s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.748 total time=   3.4s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.825 total time=   3.4s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.769 total time=   3.9s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.854 total time=   3.4s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.835 total time=   3.4s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.825 total time=   3.4s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.808 total time=   5.1s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.864 total time=   3.7s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.883 total time=   3.7s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.864 total time=   3.5s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.779 total time=   4.3s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.845 total time=   3.8s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.845 total time=   3.6s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.854 total time=   3.7s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.798 total time=   4.0s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   4.2s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.893 total time=   3.8s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.864 total time=   3.8s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.904 total time=   3.9s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.922 total time=   3.5s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.903 total time=   3.5s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.883 total time=   3.5s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b758b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9747759580612183, using {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.8992344975471497,0.0564581361167721 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.959260630607605,0.044040643731910245 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.9553771495819092,0.03962789540102695 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.8722180843353271,0.06365578555920609 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9747759580612183,0.025029280078353495 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9379574298858643,0.036671916564909625 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.8625466823577881,0.07785605714373946 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.9747759580612183,0.01802316597912194 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9380881309509277,0.03977464282479281 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8623ac4",
   "metadata": {},
   "source": [
    "# Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f412262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(11,input_dim = 11,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(14,input_dim = 11,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbc09f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ac79a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "activation_function = ['softmax', 'relu', 'tanh', 'linear']\n",
    "init = ['uniform', 'normal', 'zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cde7ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbb7885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   1.4s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   2.2s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   1.3s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   1.4s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.827 total time=   1.4s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.893 total time=   1.1s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.864 total time=   1.1s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.788 total time=   1.4s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.738 total time=   1.2s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.816 total time=   1.3s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.854 total time=   1.2s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.904 total time=   1.7s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.932 total time=   1.9s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.913 total time=   1.5s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.883 total time=   1.2s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   5.7s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.894 total time=   4.1s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.913 total time=   2.9s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.903 total time=   2.9s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.883 total time=   4.1s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   6.2s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   5.6s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   2.0s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   1.9s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.913 total time=   1.4s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.932 total time=   1.2s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.903 total time=   1.2s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.903 total time=   1.3s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.865 total time=   1.4s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.893 total time=   1.6s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.903 total time=   1.7s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.874 total time=   1.3s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.3s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   1.2s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0001d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9302651286125183, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.8216952919960022,0.15949316403473465 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.8392457127571106,0.08887087662740312 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.9264003038406372,0.03997026226748417 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.9186519861221314,0.04179472091685538 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.9302651286125183,0.03645484297710894 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.9070574998855591,0.04835495016872728 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77d963",
   "metadata": {},
   "source": [
    "# Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2124dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 11,kernel_initializer = 'uniform',activation = 'linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = adam,\n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09898a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,\n",
    "                        verbose = 0,\n",
    "                        batch_size = 40,\n",
    "                        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da9c8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,\n",
    "                   neuron2 = neuron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e42b068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.670 total time=   1.2s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.738 total time=   1.1s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.825 total time=   1.5s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.718 total time=   1.4s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.748 total time=   1.4s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.825 total time=   1.5s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.767 total time=   1.6s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.806 total time=   1.6s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.825 total time=   1.3s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.680 total time=   1.3s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.806 total time=   1.5s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.825 total time=   1.1s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.806 total time=   1.2s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.796 total time=   1.6s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.835 total time=   1.3s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.837 total time=   1.1s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.864 total time=   1.5s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.845 total time=   2.1s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.864 total time=   1.4s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.788 total time=   1.1s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.816 total time=   1.4s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.845 total time=   1.6s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.854 total time=   1.3s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.817 total time=   1.2s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.864 total time=   1.3s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.893 total time=   1.6s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.864 total time=   1.3s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.885 total time=   1.4s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.893 total time=   1.4s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.903 total time=   1.6s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.883 total time=   1.3s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,\n",
    "                    param_grid = param_grids,\n",
    "                    cv = KFold(),\n",
    "                    verbose = 10)\n",
    "\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c20a1269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9128453969955445, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.796601939201355,0.11301821329168882 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.8082524299621582,0.10217264118124691 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.8296116471290589,0.08930455638866369 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.812135910987854,0.10670340831193455 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8412248015403747,0.08212179085237079 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.8818708062171936,0.060045562857774175 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8606049418449402,0.07343045838380186 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8877333879470826,0.06117626755461539 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9128453969955445,0.04413331374983547 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf8572",
   "metadata": {},
   "source": [
    "# Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b9bca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 11,kernel_initializer = 'uniform',activation = 'linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff4d840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 0,batch_size = 40,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cb7457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7fc0d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.660 total time=   4.2s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.748 total time=   3.8s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.796 total time=   3.7s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   3.7s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.728 total time=   4.3s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.757 total time=   3.9s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.825 total time=   3.7s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   4.3s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.748 total time=   4.2s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.806 total time=   4.0s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.825 total time=   3.7s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.750 total time=   3.7s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.767 total time=   4.2s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.777 total time=   3.5s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.816 total time=   3.7s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.779 total time=   3.7s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.845 total time=   4.1s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.816 total time=   3.7s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.845 total time=   3.7s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.808 total time=   3.6s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.854 total time=   4.0s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.854 total time=   3.4s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.864 total time=   3.5s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.788 total time=   3.4s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.854 total time=   3.9s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.845 total time=   3.6s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.845 total time=   3.4s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.798 total time=   3.5s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   4.2s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   3.5s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.854 total time=   3.4s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.904 total time=   3.4s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.922 total time=   4.1s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.893 total time=   3.8s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.883 total time=   3.6s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2705895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9205750465393067, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.7907767057418823,0.11347600277863003 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.812135910987854,0.09938542909031652 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.8257281541824341,0.09231472770037459 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.8218446612358093,0.09163834920328304 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8567401170730591,0.07560510186600228 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.8761015653610229,0.06499206120814136 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8664301872253418,0.07072953775436296 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8800037264823913,0.0660992581129816 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9205750465393067,0.041750114411771615 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ed482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
